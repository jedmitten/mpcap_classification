{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s ; %(levelname)s ; %(message)s\",\n",
    "    level=logging.DEBUG\n",
    ")\n",
    "logging.getLogger(\"scapy\").setLevel(logging.CRITICAL)\n",
    "logger = logging.getLogger(\"adAPT\")\n",
    "\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_pkl = \"./data/benign_features.pkl\"\n",
    "m_pkl = \"./data/malicious_features.pkl\"\n",
    "\n",
    "b_df = pd.read_pickle(b_pkl)\n",
    "m_df = pd.read_pickle(m_pkl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_df[\"malware\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df[\"malware\"] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([b_df, m_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def shannon(counts, thing):\n",
    "    frequencies = ((i / len(thing)) for i in counts.values())\n",
    "    return - sum(f * log(f, 2) for f in frequencies)\n",
    "\n",
    "def string_shannon(string):\n",
    "    counts = Counter(string)\n",
    "    return shannon(counts, string)\n",
    "    \n",
    "\n",
    "def bytes_shannon(bytes):\n",
    "    counts = Counter(bytes)\n",
    "    return shannon(counts, bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[\"url_entropy\"] = all_df.url.apply(lambda x: string_shannon(x) if x is not None else 0)\n",
    "all_df[\"host_entropy\"] = all_df.host.apply(lambda x: string_shannon(x) if x is not None else 0)\n",
    "all_df[\"base_domain_entropy\"] = all_df.base_domain.apply(lambda x: string_shannon(x) if x is not None else 0)\n",
    "all_df[\"host_length\"] = all_df.host.apply(lambda x: len(x) if x is not None else 0)\n",
    "all_df[\"proto_packet_entropy\"] = all_df.proto_packet_cache.apply(lambda x: bytes_shannon(x) if x is not None else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df_for_ml(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    fields = [\n",
    "        \"protocol\",\n",
    "        \"app_layer\",\n",
    "        \"source_addr\", \n",
    "        \"dest_addr\",\n",
    "        \"source_port\",\n",
    "        \"dest_port\",\n",
    "        \"proto_packet_length\",\n",
    "        \"ip_packet_length\",\n",
    "        # \"url\",\n",
    "        \"url_entropy\",\n",
    "        \"host_entropy\",\n",
    "        \"base_domain_entropy\",\n",
    "        \"host_length\",\n",
    "        \"proto_packet_entropy\",\n",
    "    ]\n",
    "    new_df = df[fields]\n",
    "    new_df.loc[:, [\"source_port\", \"dest_port\"]] = new_df[[\"source_port\", \"dest_port\", ]].astype(str)\n",
    "    new_df.loc[:, [\"ip_packet_length\", \"source_port\"]] = new_df[[\"ip_packet_length\", \"source_port\", ]].astype(float)\n",
    "        \n",
    "    return pd.get_dummies(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = all_df[\"malware\"].values\n",
    "input_values = all_df.drop(\"malware\", axis=1)\n",
    "prepped = prepare_df_for_ml(input_values)\n",
    "X = np.asarray(prepped.values).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196981,)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196981, 6057)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.40, random_state=234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_cv, Y_test, Y_cv = train_test_split(X_test, Y_test, test_size=0.50, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (118188, 6057)\n",
      "X_test.shape: (39396, 6057)\n",
      "X_cv.shape: (39397, 6057)\n",
      "Y_train.shape: (118188,)\n",
      "Y_test.shape: (39396,)\n",
      "Y_cv.shape: (39397,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train.shape: {X_train.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "print(f\"X_cv.shape: {X_cv.shape}\")\n",
    "print(f\"Y_train.shape: {Y_train.shape}\")\n",
    "print(f\"Y_test.shape: {Y_test.shape}\")\n",
    "print(f\"Y_cv.shape: {Y_cv.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "\n",
    "layer_1 = layers.Dense(units=9, input_shape=(X_train.shape[-1], ), activation=\"relu\", kernel_regularizer=L2(0.01))\n",
    "layer_2 = layers.Dense(units=15, activation=\"relu\", kernel_regularizer=L2(0.01))\n",
    "layer_3 = layers.Dense(units=1, activation=\"sigmoid\", kernel_regularizer=L2(0.01))\n",
    "\n",
    "model = keras.Sequential([\n",
    "    normalizer,\n",
    "    layer_1,\n",
    "    layer_2,\n",
    "    layer_3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(),\n",
    "        tf.keras.metrics.FalseNegatives()\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3694/3694 [==============================] - 13s 3ms/step - loss: 0.2693 - binary_accuracy: 0.9565 - false_negatives: 891.0000\n",
      "Epoch 2/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.2063 - binary_accuracy: 0.9709 - false_negatives: 984.0000\n",
      "Epoch 3/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1955 - binary_accuracy: 0.9711 - false_negatives: 969.0000\n",
      "Epoch 4/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1813 - binary_accuracy: 0.9733 - false_negatives: 858.0000\n",
      "Epoch 5/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1727 - binary_accuracy: 0.9745 - false_negatives: 825.0000\n",
      "Epoch 6/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1729 - binary_accuracy: 0.9747 - false_negatives: 805.0000\n",
      "Epoch 7/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1701 - binary_accuracy: 0.9746 - false_negatives: 834.0000\n",
      "Epoch 8/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1723 - binary_accuracy: 0.9748 - false_negatives: 785.0000\n",
      "Epoch 9/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1712 - binary_accuracy: 0.9740 - false_negatives: 853.0000\n",
      "Epoch 10/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1711 - binary_accuracy: 0.9745 - false_negatives: 825.0000\n",
      "Epoch 11/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1717 - binary_accuracy: 0.9738 - false_negatives: 858.0000\n",
      "Epoch 12/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1721 - binary_accuracy: 0.9737 - false_negatives: 858.0000\n",
      "Epoch 13/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1713 - binary_accuracy: 0.9740 - false_negatives: 845.0000\n",
      "Epoch 14/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1675 - binary_accuracy: 0.9746 - false_negatives: 834.0000\n",
      "Epoch 15/15\n",
      "3694/3694 [==============================] - 12s 3ms/step - loss: 0.1695 - binary_accuracy: 0.9746 - false_negatives: 827.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x172651d90>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "1232/1232 [==============================] - 3s 2ms/step - loss: 0.1786 - binary_accuracy: 0.9784 - false_negatives: 284.0000\n",
      "test loss, test acc: [0.1785838007926941, 0.9784241914749146, 284.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, Y_test)\n",
    "print(\"test loss, test acc:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232/1232 [==============================] - 3s 2ms/step - loss: 0.1784 - binary_accuracy: 0.9791 - false_negatives: 268.0000\n",
      "cv loss and acc: [0.17835314571857452, 0.9790847301483154, 268.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"cv loss and acc: {model.evaluate(X_cv, Y_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
